## eje 2
fviz_contrib(acp, choice="var", axes = 2 )+
labs(title = "Contribuciones a la Dim 2")
## ambos ejes
fviz_contrib(acp, choice="var", axes = 1:2)+
labs(title = "Contribuciones a las dos dimensiones")
ind = get_pca_ind(acp)
ind
#Coordenadas de los individuos / observaciones en el plano de los ejes principales
head(ind$coord)
fviz_pca_ind(acp, repel = T, col.ind = "cos2")+
scale_color_gradient2(low="blue", mid="white",
high="red", midpoint=0.6)+
theme_minimal()
acp_g= fviz_pca_ind(acp, geom = "point",
habillage=iris$Species, addEllipses=TRUE,
ellipse.level= 0.95)+
labs(title = "Puntuaciones de las observaciones en las dimensiones")+
theme_minimal()
print(acp_g)
fviz_pca_biplot(acp,  label="var", habillage=iris$Species,
addEllipses=TRUE, ellipse.level=0.95) +
labs(title = "Gr?fico conjunto de observaciones y variables - Biplot")+
theme_minimal()
ACPTIUSD <- read.csv("~/Documents/CUNEF/Tecnicas de reduccion de la dimension/Datos/ACPTIUSD.csv", sep=";")
View(ACPTIUSD)
ACPTIUSD <- read.csv("~/Documents/CUNEF/Tecnicas de reduccion de la dimension/Datos/ACPTIUSD.csv", sep=";")
View(ACPTIUSD)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(gvlma)
library(MASS)
library(car)
library(bootstrap)
library(prettydoc)
nba <- read_csv("nba.csv")
head(nba) #primeras 10 observaciones
tail(nba) #ultimas 10 observaciones
names(nba)
class(nba) #clase de nba
typeof(nba) #tipo de dato interno usado por el objeto
str(nba)
length(nba) #cantidad de columnas
dim(nba) #cantidad de filas y columnas
summary(nba) #summary de los principales estadisticos
distinct(nba)
distinct(nba, Player)
duplicated(nba)
nrow(nba[duplicated(nba$Player), ]) #cuentame los repetidos
nba <- nba[!duplicated(nba$Player), ] #borro los duplicados y lo guardo con el mismo nombre de mi data set
distinct(nba) #compruebo los resultados
summarise_all(nba, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset
nba <- rename_with(nba, ~ tolower(gsub('%', '', .x, fixed = T)))
nba <- rename_with(nba, ~ tolower(gsub('3', 'three', .x, fixed = T)))
nba <- rename_with(nba, ~ tolower(gsub('/', '_', .x, fixed = T)))
nba <- nba[!is.na(nba$ts),]
nba <- nba[!is.na(nba$threepar),]
nba <- nba[!is.na(nba$ftr),]
nba <- nba[!is.na(nba$tov),]
nba <- mutate(nba, country = as.numeric(factor(nba$nba_country))) #paises
nba <- mutate(nba, team = as.numeric(factor(nba$tm))) #teams
#Calculo el salario con logaritmo neperiano en la regresion porque existe un rango de valores muy amplio.
regres01 = lm(log(salary, base = 10) ~ nba_draftnumber + age + g + mp + per + ts + threepar + ftr + orb + drb + trb  + ast + stl + blk + tov + usg + ows + dws + ws + ws_48 + obpm + dbpm + bpm + vorp + country + team,data = nba)
gvmodel <- gvlma(regres01)
summary(gvmodel)
#Aqui vemos que las variables explicativas mas significativa son draftnumber, age, g y mp
mod <- lm(log(salary, base = 10) ~ nba_draftnumber + age + g + mp + per + ts + threepar + ftr + orb + drb + trb  + ast + stl + blk + tov + usg + ows + dws + ws + ws_48 + obpm + dbpm + bpm + vorp + country + team,data = nba)
mod1 <- lm(log(salary, base = 10) ~ nba_draftnumber + age + g + mp + per + ts + threepar + ftr + orb + drb + trb  + ast + stl + blk + tov + usg + ows + dws + ws + ws_48 + obpm + dbpm + bpm + vorp,data = nba)
anova(mod1, mod)
# vemos que las variables country y team son significativas para estimar el salario de los jugadores ya que al ser el valor de p alto podemos decir que no se pueden descartar el modelo que contenga estas variables
qqPlot(regres01, labels = row.names(nba), id.method = "identify",
simulate = TRUE, main = "Q-Q Plot")
residplot <- function(fit, nbreaks=20) {
z <- rstudent(fit)
hist(z, breaks=nbreaks, freq=FALSE,
xlab="Studentized Residual",
main="Distribution of Errors")
rug(jitter(z), col="brown")
curve(dnorm(x, mean=mean(z), sd=sd(z)),
add=TRUE, col="blue", lwd=2)
lines(density(z)$x, density(z)$y,
col="red", lwd=2, lty=2)
legend("topright",
legend = c( "Normal Curve", "Kernel Density Curve"),
lty=1:2, col=c("blue","red"), cex=.7)
}
residplot(regres01)
crPlots(regres01)
vif(regres01)
sqrt(vif(regres01)) > 2
# tenemos problemas de multicolinealidad en ts, trb, usg, obpm, threepar, ows, dbpm, g, dws, bpm, mp, orb, blk, ws, vorp, per, drb, ws_48
outlierTest(regres01)
hat.plot <- function(fit) {
p <- length(coefficients(fit))
n <- length(fitted(fit))
plot(hatvalues(fit), main="Index Plot of Hat Values")
abline(h=c(2,3)*p/n, col="red", lty=2)
identify(1:n, hatvalues(fit), names(hatvalues(fit)))
}
hat.plot(regres01)
# Cooks Distance D
# identify D values > 4/(n-k-1)
cutoff <- 4/(nrow(nba)-length(regres01$coefficients)-2)
plot(regres01, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")
# Added variable plots
# add id.method="identify" to interactively identify points
avPlots(regres01, ask = FALSE, id.method = "identify")
# Influence Plot
influencePlot(regres01, id.method="identify", main="Influence Plot",
sub="Circle size is proportial to Cook's Distance" )
summary(powerTransform(nba$age))
#no vale la pena transformar la variable edad para que cumpla la normalidad porque el p valor nos indica que no es necesario
summary(powerTransform(nba$nba_draftnumber))
#no vale la pena transformar la variable draftnumber para que cumpla la normalidad porque el p valor nos indica que no es necesario
summary(powerTransform(nba$g))
#no vale la pena transformar la variable g para que cumpla la normalidad porque el p valor nos indica que no es necesario
summary(powerTransform(nba$mp))
library(MASS)
stepAIC(regres01, direction = "both")
summary(lm(formula = log(salary, base = 10) ~ nba_draftnumber + age +
mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm +
bpm, data = nba))
shrinkage <- function(fit, k=10){ require(bootstrap)
theta.fit <- function(x,y){lsfit(x,y)}
theta.predict <- function(fit,x){cbind(1,x)%*%fit$coef}
x <- fit$model[,2:ncol(fit$model)]
y <- fit$model[,1]
results <- crossval(x, y, theta.fit, theta.predict, ngroup=k)
r2 <- cor(y, fit$fitted.values)^2
r2cv <- cor(y, results$cv.fit)^2
cat("Original R-square =", r2, "\n")
cat(k, "Fold Cross-Validated R-square =", r2cv, "\n")
cat("Change =", r2-r2cv, "\n")
}
states <- as.data.frame(nba)
fit <- lm(formula = log(salary, base = 10) ~ nba_draftnumber + age +
mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm +
bpm, data=states)
shrinkage(fit)
relweights <- function(fit,...){
R <- cor(fit$model)
nvar <- ncol(R)
rxx <- R[2:nvar, 2:nvar]
rxy <- R[2:nvar, 1]
svd <- eigen(rxx)
evec <- svd$vectors
ev <- svd$values
delta <- diag(sqrt(ev))
lambda <- evec %*% delta %*% t(evec)
lambdasq <- lambda ^ 2
beta <- solve(lambda) %*% rxy
rsquare <- colSums(beta ^ 2)
rawwgt <- lambdasq %*% beta ^ 2
import <- (rawwgt / rsquare) * 100
import <- as.data.frame(import)
row.names(import) <- names(fit$model[2:nvar])
names(import) <- "Weights"
import <- import[order(import),1, drop=FALSE]
dotchart(import$Weights, labels=row.names(import),
xlab="% of R-Square", pch=19,
main="Relative Importance of Predictor Variables",
sub=paste("Total R-Square=", round(rsquare, digits=3)), ...)
return(import)
}
fit <- lm(formula = log(salary, base = 10) ~ nba_draftnumber + age +
mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm +
bpm, data = nba)
relweights(fit, col="blue")
set.seed(1234)
n <- 10
ind <- sample(1:nrow(nba), n, replace = FALSE)
muestra <- nba[ind,]
muestra <- data.frame(muestra)
muestra
prediccion <- predict(fit, newdata = muestra)
prediccion
library(glmnet)
library (boot)
library(skimr)
log_data <- nba %>% mutate(salary=log(salary))
vars <- c("player","nba_country","tm", "country", "team")
nba_sincategoricas <- log_data %>% select_at(vars(-vars))
set.seed(123)
mod1_fit1 = glm(salary ~ .,data = nba_sincategoricas,family = gaussian())
coef(mod1_fit1)
cv.err =cv.glm(nba_sincategoricas, mod1_fit1)
#delta
# A vector of length two. The first component is the raw cross-validation estimate of prediction error. The second component is the adjusted cross-validation estimate. The adjustment is designed to compensate for the bias introduced by not using leave-one-out cross-validation.
cv.err$delta
#vemos el CV error con el modelo estimado por el step AIC "both"
fit <- glm(formula = log(salary, base = 10) ~ nba_draftnumber + age + mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm + bpm, data = nba, family = gaussian())
cv.err2 = cv.glm(nba, fit)
cv.err2$delta
#tiene menor cv error el modelo estimado con el AIC
#k folds cross validation con todas las variables explicativas menos las categoricas
set.seed(123)
cv.err = cv.glm(nba_sincategoricas, mod1_fit1, K = 10)
cv.err$delta
#k folds cross validation con el modelo fit estimado por AIC
cv.err2 =cv.glm(nba, fit, K = 10)
cv.err2$delta
#observamos que tiene menor error CV
library(rsample)  # data splitting
library(glmnet)   # implementing regularized regression approaches
library(dplyr)    # basic data manipulation procedures
library(ggplot2)  # plotting
# Create training (70%) and test (30%) sets for nba data set.
# Use set.seed for reproducibility
set.seed(05112020)
nba_split <- initial_split(nba_sincategoricas, prop = .7, strata = "salary")
nba_train <- training(nba_split)
nba_test  <- testing(nba_split)
# Create training and testing feature model matrices and response vectors.
# we use model.matrix(...)[, -1] to discard the intercept
nba_train_x <- model.matrix(salary ~ ., nba_train)[, -1]
nba_train_y <- log(nba_train$salary)
nba_test_x <- model.matrix(salary ~ ., nba_test)[, -1]
nba_test_y <- log(nba_test$salary)
# What is the dimension of of your feature matrix?
dim(nba_train_x)
# Apply Ridge regression to nba data
nba_ridge <- glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 0
)
plot(nba_ridge, xvar = "lambda")
# lambdas applied to penalty parameter
nba_ridge$lambda %>% head()
# Apply CV Ridge regression to nba data
nba_ridge_cv <- cv.glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 0
)
# plot results
plot(nba_ridge_cv)
min(nba_ridge_cv$cvm) # minimum MSE
nba_ridge_cv$lambda.min     # lambda for this min MSE
log(nba_ridge_cv$lambda.min) #calculo el logaritmo para verlo visual en el grafico
nba_ridge_cv$cvm[nba_ridge_cv$lambda == nba_ridge_cv$lambda.1se]  # 1 st.error of min MSE
nba_ridge_cv$lambda.1se  # lambda for this MSE
log(nba_ridge_cv$lambda.1se)
plot(nba_ridge, xvar = "lambda")
abline(v = log(nba_ridge_cv$lambda.1se), col = "red", lty = "dashed")
coef(nba_ridge_cv, s = "lambda.1se") %>%
broom::tidy() %>%
filter(row != "(Intercept)") %>%
top_n(25, wt = abs(value)) %>%
ggplot(aes(value, reorder(row, value))) +
geom_point() +
ggtitle("Top 25 influential variables") +
xlab("Coefficient") +
ylab(NULL)
## Apply lasso regression to ames data: alpha=1
nba_lasso <- glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 1
)
plot(nba_lasso, xvar = "lambda")
# Apply CV Ridge regression to ames data
nba_lasso_cv <- cv.glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 1
)
# plot results
plot(nba_lasso_cv)
min(nba_lasso_cv$cvm)   # minimum MSE
nba_lasso_cv$lambda.min     # lambda for this min MSE
log(nba_lasso_cv$lambda.min)  #calculo el logaritmo para verlo en el grafico
nba_lasso_cv$cvm[nba_lasso_cv$lambda == nba_lasso_cv$lambda.1se]  # 1 st.error of min MSE
nba_lasso_cv$lambda.1se  # lambda for this MSE
log(nba_lasso_cv$lambda.1se) #calculo el logaritmo del lambda
plot(nba_lasso, xvar = "lambda")
abline(v = log(nba_lasso_cv$lambda.min), col = "red", lty = "dashed")
abline(v = log(nba_lasso_cv$lambda.1se), col = "red", lty = "dashed")
coef(nba_lasso_cv, s = "lambda.1se") %>%
tidy() %>%
filter(row != "(Intercept)") %>%
ggplot(aes(value, reorder(row, value), color = value > 0)) +
geom_point(show.legend = FALSE) +
ggtitle("Influential variables") +
xlab("Coefficient") +
ylab(NULL)
# minimum Ridge MSE
min(nba_ridge_cv$cvm)
# minimum Lasso MSE
min(nba_lasso_cv$cvm)
lasso    <- glmnet(nba_train_x, nba_train_y, alpha = 1.0)
elastic1 <- glmnet(nba_train_x, nba_train_y, alpha = 0.25)
elastic2 <- glmnet(nba_train_x, nba_train_y, alpha = 0.75)
ridge    <- glmnet(nba_train_x, nba_train_y, alpha = 0.0)
par(mfrow = c(2, 2), mar = c(6, 4, 6, 2) + 0.1)
plot(lasso, xvar = "lambda", main = "Lasso (Alpha = 1)\n\n\n")
plot(elastic1, xvar = "lambda", main = "Elastic Net (Alpha = .25)\n\n\n")
plot(elastic2, xvar = "lambda", main = "Elastic Net (Alpha = .75)\n\n\n")
plot(ridge, xvar = "lambda", main = "Ridge (Alpha = 0)\n\n\n")
# maintain the same folds across all models
fold_id <- sample(1:10, size = length(nba_train_y), replace=TRUE)
# search across a range of alphas
tuning_grid <- tibble::tibble(
alpha      = seq(0, 1, by = .1),
mse_min    = NA,
mse_1se    = NA,
lambda_min = NA,
lambda_1se = NA
)
tuning_grid
for(i in seq_along(tuning_grid$alpha)) {
# fit CV model for each alpha value
fit <- cv.glmnet(nba_train_x, nba_train_y, alpha = tuning_grid$alpha[i], foldid = fold_id)
# extract MSE and lambda values
tuning_grid$mse_min[i]    <- fit$cvm[fit$lambda == fit$lambda.min]
tuning_grid$mse_1se[i]    <- fit$cvm[fit$lambda == fit$lambda.1se]
tuning_grid$lambda_min[i] <- fit$lambda.min
tuning_grid$lambda_1se[i] <- fit$lambda.1se
}
tuning_grid
tuning_grid %>%
mutate(se = mse_1se - mse_min) %>%
ggplot(aes(alpha, mse_min)) +
geom_line(size = 2) +
geom_ribbon(aes(ymax = mse_min + se, ymin = mse_min - se), alpha = .25) +
ggtitle("MSE ± one standard error")
coef(fit, s = "lambda.1se") %>%
tidy() %>%
filter(row != "(Intercept)") %>%
ggplot(aes(value, reorder(row, value), color = value > 0)) +
geom_point(show.legend = FALSE) +
ggtitle("Influential variables") +
xlab("Coefficient") +
ylab(NULL)
# install.packages("plotmo")
library(plotmo)
plotres(nba_ridge)
plotres(nba_lasso)
plotres(fit)
# The first plot shows the estimated slope for each parameter for # different values of (log) lambda. Notice the different shape
# between ridge and LASSO.
# some best model
cv_ridge   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 0.0)
min(cv_ridge$cvm)
# predict
pred <- predict(cv_ridge, s = cv_ridge$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2)   # prediccion con ridge
# some best model
cv_lasso   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 1.0)
min(cv_lasso$cvm)
# predict
pred <- predict(cv_lasso, s = cv_lasso$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2)   # prediccion con lasso
# some best model
cv_net   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 0.2)
min(cv_net$cvm)
# predict
pred <- predict(cv_net, s = cv_net$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2)    #prediccion con elastic net
# Create training and testing feature model matrices and response vectors.
# we use model.matrix(...)[, -1] to discard the intercept
nba_train_x <- model.matrix(salary ~ ., nba_train)[, -1]
nba_train_y <- nba_train$salary
nba_test_x <- model.matrix(salary ~ ., nba_test)[, -1]
nba_test_y <- nba_test$salary
# What is the dimension of of your feature matrix?
dim(nba_train_x)
# Apply Ridge regression to nba data
nba_ridge <- glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 0
)
plot(nba_ridge, xvar = "lambda")
# lambdas applied to penalty parameter
nba_ridge$lambda %>% head()
# lambdas applied to penalty parameter
nba_ridge$lambda %>% head()
# Apply CV Ridge regression to nba data
nba_ridge_cv <- cv.glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 0
)
# plot results
plot(nba_ridge_cv)
min(nba_ridge_cv$cvm) # minimum MSE
nba_ridge_cv$lambda.min     # lambda for this min MSE
log(nba_ridge_cv$lambda.min) #calculo el logaritmo para verlo visual en el grafico
nba_ridge_cv$cvm[nba_ridge_cv$lambda == nba_ridge_cv$lambda.1se]  # 1 st.error of min MSE
nba_ridge_cv$lambda.1se  # lambda for this MSE
log(nba_ridge_cv$lambda.1se)
plot(nba_ridge, xvar = "lambda")
abline(v = log(nba_ridge_cv$lambda.1se), col = "red", lty = "dashed")
coef(nba_ridge_cv, s = "lambda.1se") %>%
broom::tidy() %>%
filter(row != "(Intercept)") %>%
top_n(25, wt = abs(value)) %>%
ggplot(aes(value, reorder(row, value))) +
geom_point() +
ggtitle("Top 25 influential variables") +
xlab("Coefficient") +
ylab(NULL)
## Apply lasso regression to ames data: alpha=1
nba_lasso <- glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 1
)
plot(nba_lasso, xvar = "lambda")
# Apply CV Ridge regression to ames data
nba_lasso_cv <- cv.glmnet(
x = nba_train_x,
y = nba_train_y,
alpha = 1
)
# plot results
plot(nba_lasso_cv)
min(nba_lasso_cv$cvm)   # minimum MSE
nba_lasso_cv$lambda.min     # lambda for this min MSE
log(nba_lasso_cv$lambda.min)  #calculo el logaritmo para verlo en el grafico
nba_lasso_cv$cvm[nba_lasso_cv$lambda == nba_lasso_cv$lambda.1se]  # 1 st.error of min MSE
nba_lasso_cv$lambda.1se  # lambda for this MSE
log(nba_lasso_cv$lambda.1se) #calculo el logaritmo del lambda
plot(nba_lasso, xvar = "lambda")
abline(v = log(nba_lasso_cv$lambda.min), col = "red", lty = "dashed")
abline(v = log(nba_lasso_cv$lambda.1se), col = "red", lty = "dashed")
coef(nba_lasso_cv, s = "lambda.1se") %>%
tidy() %>%
filter(row != "(Intercept)") %>%
ggplot(aes(value, reorder(row, value), color = value > 0)) +
geom_point(show.legend = FALSE) +
ggtitle("Influential variables") +
xlab("Coefficient") +
ylab(NULL)
# minimum Ridge MSE
min(nba_ridge_cv$cvm)
# minimum Lasso MSE
min(nba_lasso_cv$cvm)
lasso    <- glmnet(nba_train_x, nba_train_y, alpha = 1.0)
elastic1 <- glmnet(nba_train_x, nba_train_y, alpha = 0.25)
elastic2 <- glmnet(nba_train_x, nba_train_y, alpha = 0.75)
ridge    <- glmnet(nba_train_x, nba_train_y, alpha = 0.0)
par(mfrow = c(2, 2), mar = c(6, 4, 6, 2) + 0.1)
plot(lasso, xvar = "lambda", main = "Lasso (Alpha = 1)\n\n\n")
plot(elastic1, xvar = "lambda", main = "Elastic Net (Alpha = .25)\n\n\n")
plot(elastic2, xvar = "lambda", main = "Elastic Net (Alpha = .75)\n\n\n")
plot(ridge, xvar = "lambda", main = "Ridge (Alpha = 0)\n\n\n")
# maintain the same folds across all models
fold_id <- sample(1:10, size = length(nba_train_y), replace=TRUE)
# search across a range of alphas
tuning_grid <- tibble::tibble(
alpha      = seq(0, 1, by = .1),
mse_min    = NA,
mse_1se    = NA,
lambda_min = NA,
lambda_1se = NA
)
tuning_grid
for(i in seq_along(tuning_grid$alpha)) {
# fit CV model for each alpha value
fit <- cv.glmnet(nba_train_x, nba_train_y, alpha = tuning_grid$alpha[i], foldid = fold_id)
# extract MSE and lambda values
tuning_grid$mse_min[i]    <- fit$cvm[fit$lambda == fit$lambda.min]
tuning_grid$mse_1se[i]    <- fit$cvm[fit$lambda == fit$lambda.1se]
tuning_grid$lambda_min[i] <- fit$lambda.min
tuning_grid$lambda_1se[i] <- fit$lambda.1se
}
tuning_grid
tuning_grid %>%
mutate(se = mse_1se - mse_min) %>%
ggplot(aes(alpha, mse_min)) +
geom_line(size = 2) +
geom_ribbon(aes(ymax = mse_min + se, ymin = mse_min - se), alpha = .25) +
ggtitle("MSE ± one standard error")
coef(fit, s = "lambda.1se") %>%
tidy() %>%
filter(row != "(Intercept)") %>%
ggplot(aes(value, reorder(row, value), color = value > 0)) +
geom_point(show.legend = FALSE) +
ggtitle("Influential variables") +
xlab("Coefficient") +
ylab(NULL)
# install.packages("plotmo")
library(plotmo)
plotres(nba_ridge)
plotres(nba_lasso)
plotres(fit)
# The first plot shows the estimated slope for each parameter for # different values of (log) lambda. Notice the different shape
# between ridge and LASSO.
# some best model
cv_ridge   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 0.0)
min(cv_ridge$cvm)
# predict
pred <- predict(cv_ridge, s = cv_ridge$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2)   # prediccion con ridge
# some best model
cv_lasso   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 1.0)
min(cv_lasso$cvm)
# predict
pred <- predict(cv_lasso, s = cv_lasso$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2)   # prediccion con lasso
# some best model
cv_net   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 0.2)
min(cv_net$cvm)
# predict
pred <- predict(cv_net, s = cv_net$lambda.min, nba_test_x)
mean((nba_test_y - pred)^2)    #prediccion con elastic net

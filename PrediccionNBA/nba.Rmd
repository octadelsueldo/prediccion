---
title: "NBA"
author: "Hugo Cesar Octavio del Sueldo"
date: "10/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r data, include = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
library(knitr)
library(gvlma)
library(MASS)
library(car)

nba <- read_csv("nba.csv")
```
## Prediccion en el Data Set NBA
El data set `nba` muestra informacion sobre los salarios y los rendimientos de los jugadores de la NBA

### Exploratory data analysis of the data set

- Player: Nombre del jugador.

- Salary: Salario en dolares.

- NBA_Country: NAcionalidad del jugador.

- NBA_DraftNumber: Posición del draft.

- Age: Edad del jugador.

- Tm: Abreviatura del nombre.

- G: Partidos jugados

- MP: Minutos jugados.

- PER: Índice de eficiencia del jugador. El promedio de la liga es 15.

- TS = Porcentaje de tiro real. Tiene en cuenta los tiros de 2 puntos, los triples y los tiros libres.
                                        
- TMP: Minutos jugados por el equipo.
                                        
- 3PAr: Porcentaje de triples.
                                        
- FTr: Porcentaje de tiros libres.
                                        
- ORB%Offensive Rebound Percentage (ORB%): Porcentaje de rebotes ofensivos.

- DRB%: Porcentaje de rebote defensivo.

- TRB%: Porcentaje de rebote total.

- AST%: Porcentaje de asistencia.

- STL%: Porcentaje de robo.

- BLK%: Porcentaje de tapones.

- TOV%: Porcentaje de robo de balón antes de que el equipo contrario tire.

- USG%: Porcentaje de jugadas que estuvo involucrado un jugador, siempre que la jugada termine en uno de los tres resultados reales: intento de gol de campo, intento de tiro libre o pérdida.

- OWS: Acciones de victoria ofensivas.

- DWS: Acciones de victorias defensivas.

- WS: Un número estimado de victorias a las que un jugador ha contribuido.

- WS/48: WS por 48 minutos.

- BPM: Calcula el más/menos de un jugador respecto al rendimiento del equipo por cada 100 posesiones ofensivas.

- DBPM: Calcula el más/menos de un jugador respecto al rendimiento del equipo por cada 100 posesiones defensivas.

- BPM: Calcula el más/menos de un jugador respecto al rendimiento del equipo por cada 100 posesiones.

- VORP: Valor sobre jugador de reemplazo.
```{r }
head(nba) #primeras 10 observaciones
tail(nba) #ultimas 10 observaciones
names(nba)
class(nba) #clase de nba
typeof(nba) #tipo de dato interno usado por el objeto
str(nba)
length(nba) #cantidad de columnas
dim(nba) #cantidad de filas y columnas
summary(nba) #summary de los principales estadisticos
```
### Limpieza de valores duplicados o nulos

```{r}
distinct(nba)
distinct(nba, Player)
duplicated(nba)
nrow(nba[duplicated(nba$Player), ]) #cuentame los repetidos
nba <- nba[!duplicated(nba$Player), ] #borro los duplicados y lo guardo con el mismo nombre de mi data set
distinct(nba) #compruebo los resultados

summarise_all(nba, funs(sum(is.na(.)))) #cuentame los valores nulos en el dataset

```
#### Cambio los nombres de algunas columnas

Algunas columnas tienen nombres con los simbolos del %, comienzan con numeros o / que nos afectan a la hora de hacer calculos. Por lo tanto, vamos a modificarlas para poder trabajar correctamente.

```{r}
nba <- rename_with(nba, ~ tolower(gsub('%', '', .x, fixed = T)))
nba <- rename_with(nba, ~ tolower(gsub('3', 'three', .x, fixed = T)))
nba <- rename_with(nba, ~ tolower(gsub('/', '_', .x, fixed = T)))
```

#### Borro los nulos de las columnas que tienen valores NA

```{r}
nba <- nba[!is.na(nba$ts),]
nba <- nba[!is.na(nba$threepar),]
nba <- nba[!is.na(nba$ftr),]
nba <- nba[!is.na(nba$tov),]
```

#### Creamos las variables country y team como factor para poder sumarlas a la regresion

```{r}
nba <- mutate(nba, country = as.numeric(factor(nba$nba_country))) #paises
nba <- mutate(nba, team = as.numeric(factor(nba$tm))) #teams
```


### Regresion lineal de las variables para explicar el salario de los jugadores
```{r}
#Calculo el salario con logaritmo neperiano en la regresion porque existe un rango de valores muy amplio.
regres01 = lm(log(salary, base = 10) ~ nba_draftnumber + age + g + mp + per + ts + threepar + ftr + orb + drb + trb  + ast + stl + blk + tov + usg + ows + dws + ws + ws_48 + obpm + dbpm + bpm + vorp + country + team,data = nba)
gvmodel <- gvlma(regres01) 
summary(gvmodel)

#Aqui vemos que las variables explicativas mas significativa son draftnumber, age, g y mp

```
#### Vamos a probar si merece la pena sumar las variables country y team al modelo 

Para esto utilizaremos la funcion anova para comparar dos modelos donde el primero contiene al segundo.

```{r}
mod <- lm(log(salary, base = 10) ~ nba_draftnumber + age + g + mp + per + ts + threepar + ftr + orb + drb + trb  + ast + stl + blk + tov + usg + ows + dws + ws + ws_48 + obpm + dbpm + bpm + vorp + country + team,data = nba)
mod1 <- lm(log(salary, base = 10) ~ nba_draftnumber + age + g + mp + per + ts + threepar + ftr + orb + drb + trb  + ast + stl + blk + tov + usg + ows + dws + ws + ws_48 + obpm + dbpm + bpm + vorp,data = nba)

anova(mod1, mod)

# vemos que las variables country y team son significativas para estimar el salario de los jugadores ya que al ser el valor de p alto podemos decir que no se pueden descartar el modelo que contenga estas variables
```

### Ahora analizaremos los supuestos que no se cumplen para el modelo de regresion multilineal simple

#### Vamos a analizar la normalidad con QQ-plots

Un QQ-plots (quantile vs quantile plots) es una representación gráfica, que sirve para comparar dos distribuciones y ver si coinciden. En realidad, para comprobar si un conjunto de datos muestrales están generados por una distribución teórica como la normal 
```{r}

qqPlot(regres01, labels = row.names(nba), id.method = "identify",
       simulate = TRUE, main = "Q-Q Plot")
```
#### Vemos el histograma con su funcion de densidad 

```{r}
residplot <- function(fit, nbreaks=20) {
  z <- rstudent(fit)
  hist(z, breaks=nbreaks, freq=FALSE,
       xlab="Studentized Residual",
       main="Distribution of Errors")
  rug(jitter(z), col="brown")
  curve(dnorm(x, mean=mean(z), sd=sd(z)),
        add=TRUE, col="blue", lwd=2)
  lines(density(z)$x, density(z)$y,
        col="red", lwd=2, lty=2)
  legend("topright",
         legend = c( "Normal Curve", "Kernel Density Curve"),
         lty=1:2, col=c("blue","red"), cex=.7)
}

residplot(regres01)
```


#### Linealidad

Se grafican los valores ajustados con respecto a los predictores, si no hay problemas de linealidad se obtiene un recta sobre las que se representan los puntos.

```{r linealidad, warning = FALSE}
crPlots(regres01)
```



#### Multicolinealidad

Es la existencia de alta correlación entre los predictores puede producir problemas de imprecisión de los estimadores (las varianzas de los estimadores son mayores de lo que deberían ser). Así, los intervalos de confianza son muy anchos, hay dificultad para interpretar los coeficientes y se tiende a no rechazar las hipótesis nula de significación.

##### Método del Factor de Inflación de la Varianza

```{r}
vif(regres01)
sqrt(vif(regres01)) > 2

# tenemos problemas de multicolinealidad en ts, trb, usg, obpm, threepar, ows, dbpm, g, dws, bpm, mp, orb, blk, ws, vorp, per, drb, ws_48
```


#### Outliers

##### Observaciones anómalas
1 - Atípicos: Una observación es atípica si el residuo asociado es grande.
2 - Extrema o Apalancada: Una observación es extrema (o potencialmente influyente o apalancada) si se encuentra apreciablemente alejada del resto de observaciones de la muestra.
3 - Influyente: Una observación es influyente si la presencia de dicha observación en la muestra altera significativamente algún aspecto de la estimación del modelo.

###### Valores Atípicos
- Identificamos los valores atípicos mediante un Bonferroni p-values. En este caso solo contrasta el mayor de los residuos, si se rechaza que sea atípico se concluye que no hay atípicos.
- También se puede realizar un gráfico de los residuos estandarizados con ±2σ.

```{r}
outlierTest(regres01)
```
###### Valores extremos
- Para determinar valores extremos, se calcula el `hat statistic`, siendo la media *p/n* donde p es el número de parámetros estimados y n el tamaño muestral. Las observaciones con un valor (2 o 3 veces la media) hat alto se consideran extremas.

```{r}
hat.plot <- function(fit) {
  p <- length(coefficients(fit))
  n <- length(fitted(fit))
  plot(hatvalues(fit), main="Index Plot of Hat Values")
  abline(h=c(2,3)*p/n, col="red", lty=2)
  identify(1:n, hatvalues(fit), names(hatvalues(fit)))
}
hat.plot(regres01)
```
###### Valores Influyentes
Hay dos métodos par identificar observaciones influyentes:

- La distancia de Cook (D-estadístico)
- Gráficos added variable
```{r}
# Cooks Distance D
# identify D values > 4/(n-k-1) 
cutoff <- 4/(nrow(nba)-length(regres01$coefficients)-2)
plot(regres01, which=4, cook.levels=cutoff)
abline(h=cutoff, lty=2, col="red")
```

```{r linealidad-plot, warning = FALSE}
# Added variable plots
# add id.method="identify" to interactively identify points
avPlots(regres01, ask = FALSE, id.method = "identify")
```

```{r influence-plot, warning = FALSE}
# Influence Plot
influencePlot(regres01, id.method="identify", main="Influence Plot", 
              sub="Circle size is proportial to Cook's Distance" )
```

#### Vamos a verificar si merece la pena hacer una transformacion de las variables para ajustar el modelo

La funcion powerTransform nos indica si merece la pena hacer una transformacion polinomial en la variable explicativa para ajustar el modelo.

```{r}

summary(powerTransform(nba$age))  
#no vale la pena transformar la variable edad para que cumpla la normalidad porque el p valor nos indica que no es necesario
summary(powerTransform(nba$nba_draftnumber))
#no vale la pena transformar la variable draftnumber para que cumpla la normalidad porque el p valor nos indica que no es necesario
summary(powerTransform(nba$g)) 
#no vale la pena transformar la variable g para que cumpla la normalidad porque el p valor nos indica que no es necesario
```

#### Métodos de Selección
##### Selección Best Subset
##### Selección Stepwise
- Forward Stepwise
- Backward Stepwise
- Mixto
```{r}
library(MASS)
stepAIC(regres01, direction = "both")
```


#### Hacemos un summary al modelo con el menor AIC para ver su R2


```{r}
summary(lm(formula = log(salary, base = 10) ~ nba_draftnumber + age + 
    mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm + 
    bpm, data = nba))
```


#### Cross-Validation

In cross-validation, a portion of the data is selected as the training sample, and a portion is selected as the hold-out sample. A regression equation is developed on the training sample and then applied to the hold-out sample. Because the hold-out sam- ple wasn’t involved in the selection of the model parameters, the performance on this sample is a more accurate estimate of the operating characteristics of the model with new data.

In k-fold cross-validation, the sample is divided into k subsamples. Each of the k sub- samples serves as a hold-out group, and the combined observations from the remaining k – 1 subsamples serve as the training group. The performance for the k prediction equations applied to the k hold-out samples is recorded and then averaged. (When k equals n, the total number of observations, this approach is called jackknifing.)

You can perform k-fold cross-validation using the crossval() function in the bootstrap package. The following listing provides a function (called shrinkage()) for cross-validating a model’s R-square statistic using k-fold cross-validation.

```{r}

library(bootstrap)
shrinkage <- function(fit, k=10){ require(bootstrap)
theta.fit <- function(x,y){lsfit(x,y)}
theta.predict <- function(fit,x){cbind(1,x)%*%fit$coef}
x <- fit$model[,2:ncol(fit$model)]
y <- fit$model[,1]
results <- crossval(x, y, theta.fit, theta.predict, ngroup=k)
r2 <- cor(y, fit$fitted.values)^2
r2cv <- cor(y, results$cv.fit)^2
cat("Original R-square =", r2, "\n")
cat(k, "Fold Cross-Validated R-square =", r2cv, "\n")
cat("Change =", r2-r2cv, "\n")
}
states <- as.data.frame(nba)
fit <- lm(formula = log(salary, base = 10) ~ nba_draftnumber + age + 
    mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm + 
    bpm, data=states)
shrinkage(fit)

```
You can see that the R-square based on the sample (0.5534) is overly optimistic. A better estimate of the amount of variance in salary that this model will account for with new data is the cross-validated R-square (0.5019). (Note that observations are assigned to the k groups randomly, so you’ll get a slightly different result each time you execute the shrinkage() function.)


#### Relative importance of each variable 

“Which variables are most important in predicting the outcome?” You implicitly want to rank-order the predictors in terms of relative importance. There may be practical grounds for asking the second question. For example, if you could rank-order leadership practices by their relative importance for organizational success, you could help managers focus on the behaviors they most need to develop.

There have been many attempts to develop a means for assessing the relative importance of predictors. The simplest has been to compare standardized regression coefficients. Standardized regression coefficients describe the expected change in the response variable (expressed in standard deviation units) for a standard deviation change in a predictor variable, holding the other predictor variables constant. You can obtain the standardized regression coefficients in R by standardizing each of the variables in your dataset to a mean of 0 and standard deviation of 1 using the scale() function, before submitting the dataset to a regression analysis.

```{r}
relweights <- function(fit,...){
R <- cor(fit$model)
nvar <- ncol(R)
rxx <- R[2:nvar, 2:nvar]
rxy <- R[2:nvar, 1]
svd <- eigen(rxx)
evec <- svd$vectors
ev <- svd$values
delta <- diag(sqrt(ev))
lambda <- evec %*% delta %*% t(evec)
lambdasq <- lambda ^ 2
beta <- solve(lambda) %*% rxy
rsquare <- colSums(beta ^ 2)
rawwgt <- lambdasq %*% beta ^ 2
import <- (rawwgt / rsquare) * 100
import <- as.data.frame(import)
row.names(import) <- names(fit$model[2:nvar]) 
names(import) <- "Weights"
import <- import[order(import),1, drop=FALSE]
dotchart(import$Weights, labels=row.names(import),
  xlab="% of R-Square", pch=19,
  main="Relative Importance of Predictor Variables", 
  sub=paste("Total R-Square=", round(rsquare, digits=3)), ...)
return(import)
}

fit <- lm(formula = log(salary, base = 10) ~ nba_draftnumber + age + 
    mp + per + ts + trb + ast + tov + usg + dws + ws_48 + obpm + 
    bpm, data = nba)
relweights(fit, col="blue")
```


